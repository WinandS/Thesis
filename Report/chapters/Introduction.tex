\chapter{Introduction}
In software and hardware development, verification and validation is the process of checking that a system meets specifications and that it fulfills its intended purpose. It may also be referred to as quality control. It is normally the responsibility of testers as part of the development lifecycle \cite{intro:wiki}.\nline
In other words, the questions
\begin{itemize}
	\item Are we building the product right? (Verification)
	\item Are we building the right product? (Validation)
\end{itemize}
are becoming more and more important to designers as consumers become increasingly demanding.
\npar
The software development industry has invested enormously in new verification methods and is still building toward better verification. Software developers have an abundance of support tools available for their respective languages (e.g. C, Java, Python, etc.). These tools help the programmer by automating a lot of the actions required to write, validate, and document the code.
\npar
Hardware development has always lagged behind however. Support tools for hardware development languages (HDLs) like VHDL and Verilog are limited and often outdated. Modernising verification methods for HDLs is progressing slower than for programming languages. There is still a lot of room for improvement in this area.
\npar
In light of this, this report introduces a way to improve VHDL design verification. More specifically, provide a way to easily design tests and simulate them, while at the same time helping to document the design and automatically comparing the simulation result to the design documentation (or specification). The operation of the resulting software is illustrated below.%
\MijnFig{width=\textwidth}{images/overview}{Operation overview of the new system}{fig:overview}\nline
The tool starts from two input files: the design to be tested and the source file, which specifies a test. A test checks the design for compliance with its specification. These two files are processed and a VHDL test is built for the design. This test is simulated and its results are saved as the simulation wave traces. These wave traces show how the design behaves by visualising the input and output signals during the test. At the same time the documentation wave traces are derived from the source file. These wave traces show how the system should behave. They are compared to those generated by the simulation. If the simulation result is as expected, the design has passed the test and has passed the test. It is compliant to what is specified in the documentation. 
\npar
To understand the purpose and use of the proposed tool, a short introduction in the verification process is necessary.
\newpage\noindent
Whenever a hardware component is implemented, its behavior is defined the design file. The behavior of the component is often documented visually by showing input and expected output wave traces. Wave traces are the visualisation of a signals values over time. An example for an AND-gate is shown below. Input signals are connected to a design's input and the output signals represent the expected output of the design.\nline
\MijnFig{width=.9\textwidth}{images/andgate_example}{AND-gate wave trace example}{fig:wave_trace_example}\nline
The behavior is tested by attaching it to a so called testbench.  Historically, it is also written in a HDL. It describes the environment in which the design is to be tested. In this testbench one or more tests can be performed by attaching certain input signals to the designs input ports. Creating this testbench is the first step in the verification process. The design being tested is often referred to as the Device Under Test (DUT) or the Unit Under Test (UUT). Figure \ref{fig:tb} illustrates the hierarchy of a testbench.
\MijnFig{width=.9\textwidth}{images/simulation}{Hierarchy of a testbench}{fig:tb}\nline
The second step of the verification process is to simulate the tests described in a testbench. A simulation yields output signals depending on the input signals and the behavior of the DUT. Figure \ref{fig:modelsim} shows an example of a simulation output (simulation wave traces). If a design functions correctly, these wave traces are equal to those in the documentation.
\MijnFig{width=.9\textwidth}{images/modelsim}{Modelsim simulated wave traces }{fig:modelsim}\nline
To verify a design, ideally,  every possible input has to be simulated in a test and have its corresponding simulated output compared to the expected output specified in the documentation. This would mean that the tests cover 100\% of the design code. In practice trying to reach this percentage is not economically desirable, but designers still strive to reach an acceptably high coverage percentage. Checking whether test results are in accordance with the documentation is the last step in the verification cycle.
\npar
The complete verification cycle is shown in figure \ref{fig:ver_old}. Starting from  a VHDL design,
\begin{inparaenum}[a)]
	\item a testbench is created, 
	\item then it is simulated and
	\item finally its wave traces are analysed.
\end{inparaenum}
\npar
\MijnFig{width=\textwidth}{images/validation_old}{Traditional verification cycle}{fig:ver_old}\noindent
Each step can be optimized in their own way. The proposed tool will focus on streamlining the first and the last step, relying on existing simulation tools to handle the second step. It will use a new source file to help generate documentation wave traces, while at the same time using that file to create testbenches and analyse simulation wave traces. The improved verification cycle is shown in figure \ref{fig:ver_new}. Figure \ref{fig:overview} shows these steps in detail.\nline
\MijnFig{width=\textwidth}{images/validation_new}{Improved verification cycle}{fig:ver_new}\nline
