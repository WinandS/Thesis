%De volgende delen (Probleembeschrijving - Functionele analyse - Technische analyse - Technisch ontwerp) tellen samen ongeveer twintig pagina’s. De projectdefinitie is bedoeld voor de opdrachtgever (bv. de algemene directeur van het bedrijf waar je werkt) en moet kort zijn. Maak duidelijk waarover het project gaat en onderstreep het belang van het onderzoek/de ontwikkeling. De probleembeschrijving mag niet te technisch zijn want de opdrachtgever is vooral geïnteresseerd in resultaten of producten: hij verwacht activiteiten of producten en houdt zich niet bezig met technische aspecten. Mogelijke onderdelen van de probleembeschrijving: beschrijving van probleem dat moet worden opgelost - doel van onderzoek - specificaties van product (eventueel lastenboek) - inhoud gebruikersinterface

\chapter{Problem analysis}%1-2 pag
The classic (V)HDL verification process is shown in the figure \ref{fig:ver_old}. Starting from a VHDL design a testbench is created. The testbench is then simulated, which yields the simulation wave traces. These wave traces are then visually checked for compliance with the documentation wave traces. If the design behaves as the documentation specifies, the verification process is complete. If the design does not behave accordingly, the design is reviewed and the process is run again. The behavior of the design is described in the documentation.
\npar
The least efficiënt steps in this process are the creation of the test benches (top) and the visual comparison of wave traces (bottom). They will be the primary elements of focus in this report.
\npar
The first element of focus is the creation of testbenches. Designers either have to rely on older, outdated, testbenches who might not be self checking or design a new testbench manually. Self checking testbenches are testbenches that report any irregular behavior automatically, whereas conventional testbenches simply simulate output signals and leave the analysis to the designer. Testbenches are often at least partly written manually and creating them is a repetitive task. This means writing a test for every aspect is time consuming and prone to human error. If this process could be automated, a lot of time and work could be saved. At the same time writing the documentation is a tedious task, where every function has to be explained. Documentation often includes example wave traces. As can be see from image \ref{fig:wave_trace_example} and \ref{fig:modelsim}, which are documentation wave traces and simulated wave traces a certain feature respectively, these wave traces are exactly the same (considering the design functions as documented). Although the way they were created differs greatly, the documentation and test result essentially hold the same information. In theory it would be possible to devise a system that could build both the documentation wave traces and the test for a specific feature from the same information, eliminating the need to create testbenches manually, while still offering the same functionality.
\npar
In short, the system should be able to build a self checking testbench automatically based on the information in the documentation.
\npar
The second element of focus is comparing the expected output in the documentation to the simulated output of the testbenches, or simply wave trace analysis. Self checking testbenches perform an analysis during simulation and show errors to the user by logging them to a file or terminal, but testbenches that are not self checking leave all wave trace analysis to the user. Comparing wave traces visually is not ideal, because the complexity of some tests and their corresponding wave traces is considerable, which often results in a staring contest between designer and simulation result. Because of this, the proposed solution will not only build self checking testbenches, but will process the analysis result and show it in a user friendly and easy to understand format. Building on the presumption that there is a way to build both documentation wave traces and testbenches from the same information, we can say that the documentation wave traces should be exactly the same as the simulated wave traces. Because of this wave trace analysis boils down to checking these two wave trace files for discrepancies and showing the difference in a clear way to the user.
\npar
In short, the system should be able to take the error reports logged by the self checking testbench and show them in an easily understandable way to a user.
\npar
The resulting software package should be easy to use, that is why a simple gui will be added where the user can input the source file and the VHDL design to be tested. From this information the testbench can be created and simulated by pressing a button. Finally the simulated wave traces are automatically compared to the documentations and the result is shown.
\npar
Lastly a short analysis will be made regarding the use of this software and the benefits it provides over existing frameworks.
\npar
To summarise this report will try to answer the following questions:
\begin{itemize}
	\item Can we design a system that will streamline the process of design validation?
	\subitem Can we design a system that can create self checking testbenches and documentation wave traces from the same source?
	\subitem Can we optimise wave trace analysis based on this system?
	\item Does this system provide any benefits over existing verification frameworks?	
\end{itemize}